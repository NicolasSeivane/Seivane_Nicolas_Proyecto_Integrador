\documentclass[a4paper,10pt]{book}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
%\usepackage{mathtools}
\usepackage{graphicx}
\usepackage[margin=1in]{geometry}
%\usepackage[spanish]{babel}
\usepackage[hidelinks]{hyperref}
\usepackage{fancyhdr}
\usepackage{incgraph,tikz}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsfonts}
\usepackage{babel}
\usepackage{color}
\usepackage{listings}
\usepackage{float}
\usepackage{tikz}
\usepackage{adjustbox}
\usepackage{natbib}
\usepackage{subcaption}
\usepackage{xcolor}
\usepackage{titlepic}
\usepackage{amsmath}
\usepackage{cleveref}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{float}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{colortbl}
\usepackage{multirow}



\usepackage{listings}
\lstset{ %
basicstyle=\footnotesize,       % the size of the fonts that are used for the code
numbers=none,                   % where to put the line-numbers
numberstyle=\footnotesize,      % the size of the fonts that are used for the line-numbers
stepnumber=1,                   % the step between two line-numbers. If it is 1 each line will be numbered
numbersep=10pt,                  % how far the line-numbers are from the code
backgroundcolor=\color{white},  % choose the background color. You must add \usepackage{color}
showspaces=false,               % show spaces adding particular underscores
showstringspaces=false,         % underline spaces within strings
showtabs=false,                 % show tabs within strings adding particular underscores
frame=single,           % adds a frame around the code
tabsize=4,          % sets default tabsize to 2 spaces
captionpos=b,           % sets the caption-position to bottom
breaklines=true,        % sets automatic line breaking
breakatwhitespace=false,    % sets if automatic breaks should only happen at whitespace
escapeinside={\%*}{*)}          % if you want to add a comment within your code
}

\usetikzlibrary{arrows}

\captionsetup[subfigure]{subrefformat=simple,labelformat=simple}

\renewcommand{\contentsname}{\'Indice General}
\renewcommand{\listfigurename}{\'Indice de Figuras}
\renewcommand{\listtablename}{\'Indice de Tablas}
\renewcommand{\lstlistingname}{Salida}
\renewcommand\tablename{Tabla}
\renewcommand{\figurename}{Figura}
\renewcommand\thesubfigure{(\alph{subfigure})}
\renewcommand{\baselinestretch}{1.2} 

\makeatletter
\def\verbatim{\small\@verbatim \frenchspacing\@vobeyspaces \@xverbatim}
\makeatother

\pagestyle{fancy}

\restylefloat{table}


\definecolor{TPcolor}{HTML}{A9D18E} % Verde claro para TP
\definecolor{TNcolor}{HTML}{D9EAD3} % Verde muy claro para TN
\definecolor{FPcolor}{HTML}{F4CCCC} % Rojo muy claro para FP
\definecolor{FNcolor}{HTML}{E06666} % Rojo claro para FN

\title{Comparación de Técnicas de Aprendizaje
	Automático Supervisado}
\author{Autor: Nicolás Seivane \\ Tutor: Andrea Rey}
\date{Fecha \\ Universidad Nacional de Hurlingham}
\titlepic{\vspace{12cm}\includegraphics[width=0.15\textwidth]{logo.jpg}}

\begin{document}

\maketitle


\tableofcontents
\listoffigures
\listoftables

\chapter*{Resumen}

\chapter{Introducción}


Describir el problema que se desea resolver

\section{Motivación}

Explicar porqué estudiamos este problema, para qué sirve, cuál es el impacto y en qué áreas.


\section{Estado del Arte}


En esta sección se realiza una descripción de algunos de los métodos más importantes existentes en la bibliografía describiendo el problema y el método utilizado por cada autor. Se cita la bibliografía. 
 
\section{Conjuntos de datos Utilizados}

Se realiza este informe de registros, atributos y métricas relevantes luego de eliminar duplicados, datos faltantes y anormales.

\subsection{Dataset Binario: Insuficiencia  Cardíaca Predicción}

\vspace{0.2cm}
\begin{flushleft}
	\textbf{Titulo Original}:  Heart Failure Prediction Dataset \\
	\textbf{Citación}: fedesoriano. (September 2021). Heart Failure Prediction Dataset. Retrieved [Date Retrieved] from \underline{\href{https://www.kaggle.com/fedesoriano/heart-failure-prediction}{https://www.kaggle.com/fedesoriano/heart-failure-prediction}}
	
\end{flushleft}

\begin{flushleft}
	\textbf{Descripción}: Enfermedades cardiovasculares son la causa numero uno de muerte globalmente, tomando un estimado de 17.9 millones de vidas cada año, que son aproximadamente 31\% de todas las muertes globales.\\
	\vspace{0.2cm}
	Este dataset fue creado mediante la combinación de distintos dataset disponibles independientes pero no combinados anteriormente. 5 datasets de información cardíaca están combinados en 11 atributos comunes logrando el dataset mas grande de informacion de enfermedades cardiovasculares utilizado para investigación. Los 5 datasets utilizados para la creación de este son:\\
	\begin{itemize}
		\item Cleveland: 303 observaciones
		\item Hungarian: 294 observaciones
		\item Switzerland: 123 observaciones
		\item Long Beach VA: 200 observaciones 
		\item Stalog (Heart) Data Set: 270 observaciones
	\end{itemize}
	
	
\end{flushleft}


\begin{flushleft}
	\textbf{Cantidad de registros}: 918\\
	\textbf{Cantidad de registros valiosos}: 743\\
	\textbf{Cantidad de atributos}: 11\\
	\textbf{Atributos Categóricos}: 5\\
	\textbf{Atributos Numéricos}: 6\\
	
\end{flushleft}

\begin{flushleft}
	Los atributos son (Algunos son numéricos en el dataset pero son codificaciones de categóricos):
	
	
	\vspace{0.2cm}
	\centering
	\begin{tabular}{|l|c|c|c|}
		\hline
		\textbf{Atributo} & \textbf{Tipo de dato} & \textbf{¿Esta codificado?} & \textbf{Unidad} \\
		\hline
		Age        & Numérico (int) & No & Años \\
		\hline
		Sex             & Categorico (string) & No & -\\
		\hline
		ChestPainType               & Categorico (string) & No & -\\
		\hline
		RestingBP     & Numérico (int) & No & mm Hg\\
		\hline
		Cholesterol    & Numérico (int) & No & mm/dl\\
		\hline
		FastingBS                 & Numérico (int) & Si & "mg/dl"\\
		\hline
		RestingECG                      & Categorico (string) & No & -\\
		\hline
		MaxHR    & Numérico (int) & No & -\\
		\hline
		ExerciseAngina               & Categorico (string) & No & -\\
		\hline
		Oldpeak                 & Numérico (float) & No & ST en depresión\\
		\hline
		$ST\_Slope$                 & Categorico (string) & No & -\\
		\hline
		HeartDisease                 & Numérico (int)     & Si & -\\
		\hline
		\hline
	\end{tabular}
\end{flushleft}

\begin{flushleft}
	
	\underline{\textbf{Descripción atributos:}}\\
	\vspace{0.2cm}
	
	\textbf{Age}: Edad de los pacientes. Tiene media: 53 años, valor máximo: 77 y valor mínimo: 28, con proporciones de edad bastante bien distribuidas, siendo la menor de 0.11\% para algunas edades y la mayor de 4.14\% para otras edades, teniendo otras distribuciones entre estos dos rangos\\
	\vspace{0.2cm}
	\textbf{Sex}: Sexo de los pacientes; hay 78.98\% M (masculinos) y  hay 21.02\%  F (femeninos)\\
	\vspace{0.2cm}
	\textbf{ChestPainType}: Tipo del dolor en el pecho;    Hay 18.85\% ATA, hay 22.11\% NAP, hay 54.03\% ASY, hay 5.01\% TA. [TA: Typical Angina, ATA: Atypical Angina, NAP: Non-Anginal Pain, ASY: Asymptomatic]\\
	\vspace{0.2cm}
	\textbf{RestingBP}: Presión sanguínea en reposo, donde hay 51.09\% de mujeres, codificadas en 1 y 48.91\% de hombres, codificados en 0.\\
	\vspace{0.2cm}
	\textbf{Cholesterol}: Colesterol serico, la medida total de colesterol en sangre; tiene media: 199.02, valor máximo: 603.00 y valor mínimo: 0.00. Miligramos por decilitro \\
	\vspace{0.2cm}
	\textbf{FastingBS}: Glucosa en sangre en ayuno; hay 76.66\% Glucosa en sangre < 120 mg/dl codificado en 0 y hay 23.34\% Glucosa en sangre > 120 mg/dl codificado en 1\\
	\vspace{0.2cm}
	\textbf{RestingECG}: Resultados de electrocardiogramas en reposo; hay 60.09\% codificado en Normal, hay 19.41\% codificado en ST y hay 20.50\% codificado en LVH  [Normal: Normal, ST: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV), LVH: showing probable or definite left ventricular hypertrophy by Estes' criteria] \\
	\vspace{0.2cm}
	\textbf{MaxHR}: Máximo ritmo cardíaco registrado, tiene media: 136.79, valor maximo: 202.00 y valor minimo: 60.00 \\
	\vspace{0.2cm}
	\textbf{ExerciseAngina}:Angina producido por ejercicio, dolor en el pecho; hay 59.54\% No codificado en N y hay 40.46\% Si codificado en Y \\
	\vspace{0.2cm}
	\textbf{Oldpeak}: Valor máximo de depresión del segmento ST (en milímetros) registrado en todas las derivaciones contiguas durante una prueba de esfuerzo. Forma parte del cálculo del riesgo de un paciente de isquemia o infarto de miocardio; valores más altos indican un mayor riesgo de enfermedad coronaria; tiene media: 0.90, valor maximo: 6.20 y valor minimo: -0.10 \\
	\vspace{0.2cm}
	\textbf{ST\_Slope}: The slope of the peak exercise ST segment; hay 43.08\%, hay 50.05\% Flat y hay 6.87\% Down [Up: upsloping, Flat: flat, Down: downsloping]\\
	\vspace{0.2cm}
	\textbf{HeartDisease}:Variable de salida de si posee una enfermedad cardíaca; hay 44.71\% No codificado en 0 y hay 55.29\% Si codificado en 1\\
	
\end{flushleft}

\textbf{Función Objetivo Inicial}: Donde la variable salida es $HeartDisease$, no hay una variable que se use como condición:

\[
f(x)  =
\begin{cases}
	\text{'1'} & \text{si ??} \\
	\text{'0'} & \text{si ??} \\
	
\end{cases}
\]

\subsection{Dataset Multiclase: Cardiotocografía Predicción}

\begin{flushleft}
	\textbf{Titulo Original}: Cardiotocography\\
	\textbf{Cita}: Campos, D. \& Bernardes, J. (2000). Cardiotocography [Dataset]. UCI Machine Learning Repository.  \underline{\href{https://doi.org/10.24432/C51S4N.}{https://doi.org/10.24432/C51S4N.}}\\
	
\end{flushleft}

\begin{flushleft}
	
	\textbf{Descripción}: La cardiotocografía (CTG) es un registro continuo de la frecuencia cardíaca fetal que se obtiene mediante un transductor de ultrasonidos colocado en el abdomen materno. La CTG se utiliza ampliamente durante el embarazo como método para evaluar el bienestar fetal, sobre todo en embarazos con mayor riesgo de complicaciones.\\
	\vspace{0.2cm}
	Se procesaron automáticamente 2126 cardiotocogramas fetales (CTG) y se midieron sus características diagnósticas. Tres obstetras expertos clasificaron los CTG y se les asignó una etiqueta de clasificación consensuada. La clasificación se realizó tanto con respecto a un patrón morfológico (A, B, C...) como al estado fetal (N, S, P).\\
	
	
	
\end{flushleft}


\begin{flushleft}
	\textbf{Cantidad de registros}: 2126\\
	\textbf{Cantidad de registros valiosos}: 2115\\
	\textbf{Cantidad de atributos}: 21\\
	\textbf{Atributos Categóricos}: 0\\
	\textbf{Atributos Numéricos}: 21\\
	
\end{flushleft}

\begin{flushleft}
	Los atributos son (Algunos son numéricos en el dataset pero son codificaciones de categóricos):
	
	
	\vspace{0.2cm}
	\centering
	\begin{tabular}{|l|c|}
		\hline
		\textbf{Atributo} & \textbf{Tipo de dato} \\
		\hline
		LB        & Numérico (int)\\
		\hline
		AC             & Numérico \\
		\hline
		FM               & Numérico (float)\\
		\hline
		UC     & Numérico (float) \\
		\hline
		DL    & Numérico (float)\\
		\hline
		DS                 & Numérico (float)\\
		\hline
		DP                      & Numérico (float)\\
		\hline
		ASTV    & Numérico (int) \\
		\hline
		MSTV               & Numérico (float) \\
		\hline
		ALTV                 & Numérico (int) \\
		\hline
		MLTV                 & Numérico (float)\\
		\hline
		Width                 & Numérico (int) \\
		\hline
		Min                 & Numérico (int) \\
		\hline
		Max                 & Numérico (int)  \\
		\hline
		Nmax                 & Numérico (int)  \\
		\hline
		Nzeros                 & Numérico (int)  \\
		\hline
		Mode                 & Numérico (int)  \\
		\hline
		Mean                 & Numérico (int) \\
		\hline
		Median                 & Numérico (int)  \\
		\hline
		Variance                 & Numérico (int) \\
		\hline
		Tendency                 & Numérico (int) \\
		\hline
		NSP                 & Categórico (string) \\
		\hline
	\end{tabular}
\end{flushleft}


\begin{flushleft}
	\underline{\textbf{Descripción atributos:}}\\
	
	\vspace{0.2cm}
	
	\textbf{LB}:Frecuencia cardíaca fetal basal (latidos por minuto). Tiene media: 133.30, valor máximo: 160.00 y valor mínimo: 106.00\\
	
	
	\vspace{0.2cm}
	\textbf{AC}: Número de aceleraciones por segundo. Tiene media: 0.00, valor máximo: 0.02 y valor mínimo: 0.00 \\
	\vspace{0.2cm}
	
	
	\textbf{FM}:Número de movimientos fetales por segundo. Tiene media: 0.01, valor máximo: 0.48 y valor mínimo: 0.00 \\
	\vspace{0.2cm}
	
	
	
	\textbf{UC}: Número de contracciones uterinas por segundo.  Tiene media: 0.00, valor máximo: 0.01 y valor mínimo: 0.00\\
	\vspace{0.2cm}
	
	
	
	\textbf{DL}:Número de desaceleraciones leves por segundo. Tiene media: 0.00, valor máximo: 0.01 y valor mínimo: 0.00  \\
	\vspace{0.2cm}
	
	
	
	\textbf{DS}: Número de desaceleraciones severas por segundo. Hay un 99.67\% con valor 0.0 y un 0.33\% con un valor 0.001\\
	\vspace{0.2cm}
	
	
	
	\textbf{DP}:Número de desaceleraciones prolongadas por segundo.  Hay un 91.58\% con valor 0.0, 3.40\% con un valor 0.002, 1.13\% con un valor 0.003, 3.31\% con un valor 0.001, 0.43\% con un valor 0.004 y 0.14\% con un valor 0.005\\
	\vspace{0.2cm}
	
	
	
	\textbf{ASTV}: Porcentaje de tiempo con variabilidad anormal a corto plazo. Tiene media: 46.98, valor máximo: 87.00 y valor mínimo: 12.00 \\
	\vspace{0.2cm}
	
	
	
	\textbf{MSTV}: Valor medio de la variabilidad a corto plazo. Tiene media: 1.34, valor máximo: 7.00 y valor mínimo: 0.20 \\
	\vspace{0.2cm}
	
	
	\textbf{ALTV}: Porcentaje de tiempo con variabilidad anormal a largo plazo. Tiene media: 9.79, valor máximo: 91.00 y valor mínimo: 0.00 \\
	\vspace{0.2cm}
	
	
	\textbf{MLTV}: Valor medio de la variabilidad a largo plazo. Tiene media: 8.17, valor máximo: 50.70 y valor mínimo: 0.00\\
	\vspace{0.2cm}
	
	
	\textbf{Width}: Ancho del histograma de FCF. Tiene media: 70.51, valor máximo: 180.00 y valor mínimo: 3.00\\
	\vspace{0.2cm}
	
	
	
	\textbf{Min}: Mínimo del histograma de FCF. Tiene media: 93.57, valor máximo: 159.00 y valor mínimo: 50.00\\
	\vspace{0.2cm}
	
	\textbf{Max}: Máximo del histograma de FCF. Tiene media: 164.09, valor máximo: 238.00 y valor mínimo: 122.00\\
	\vspace{0.2cm}
	
	\textbf{Nmax}: Número de picos del histograma. Tiene media: 4.08, valor máximo: 18.00 y valor mínimo: 0.00\\
	\vspace{0.2cm}
	
	\textbf{Nzeros}: Número de ceros del histograma.  Hay un 76.26\% con valor 0, 17.30\% con un valor 1, 0.99\% con un valor 3, 5.11\% con un valor 2, 0.09\% con un valor 4, 0.05\% con un valor 10, 0.09\% con un valor 5, 0.05\% con un valor 8, y  0.05\% con un valor 7. \\
	\vspace{0.2cm}
	
	\textbf{Mode}: Moda del histograma. Tiene media: 137.45, valor máximo: 187.00 y valor mínimo: 60.00\\
	\vspace{0.2cm}
	
	\textbf{Mean}: Promedio del histograma. Tiene media: 134.60, valor máximo: 182.00 y valor mínimo: 73.00\\
	\vspace{0.2cm}
	
	\textbf{Median}: Media del histograma. Tiene media: 138.08, valor máximo: 186.00 y valor mínimo: 77.00\\
	\vspace{0.2cm}
	
	\textbf{Variance}: Varianza del histograma. Tiene media: 18.89, valor máximo: 269.00 y valor mínimo: 0.00\\
	\vspace{0.2cm}
	
	\textbf{Tendency}: Tendencia del histograma.  Hay un 39.67\% con valor 1, 52.53\% con un valor 0 y 8.27\% con un valor -1\\
	\vspace{0.2cm}
	
	\textbf{CLASS}:código de clasificación del estado fetal (N=normal; S=sospechoso; P=patológico).  Hay un 13.81\% con valor Sospechoso, 77.92\% con un valor Normal, 8.27\% con un valor Patológico.\\
	\vspace{0.2cm}
	
\end{flushleft}

\textbf{Función Objetivo Inicial}: Donde la variable salida es $CLASS$:

\[
f(x)  =
\begin{cases}
	\text{'Sospechoso'} & \text{si ??} \\
	\text{'Normal'} & \text{si ??} \\
	\text{'Patológico'} & \text{si ??} \\
	
\end{cases}
\]



\chapter{Métricas de Rendimiento Utilizadas}

\section{Introducción}

Dentro del objetivo de este trabajo es evaluar el desempeño calificador de cada modelo de \textit{Machine Learning}. Para alcanzar este objetivo, se utilizaran \textbf{métricas de rendimiento} que permiten cuantificar la capacidad del algoritmo de clasificar.

\textbf{La importancia de las métricas} se ubica en que el objetivo central de estos algoritmos no es simplemente obtener un buen rendimiento en los datos utilizados para construir el modelo, sino en su \textbf{capacidad de generalización}, su habilidad para funcionar correctamente con entradas nuevas y previamente no observadas (no utilizadas en el entrenamiento).

Para la obtención de las métricas y entrenamiento de algoritmo se utilizara la estrategia de \textbf{Validación Cruzada $k$-fold}, donde el conjunto de datos se divide en $k$ grupos (o pliegues, en una traducción más fiel) del mismo tamaño, donde en cada iteración un grupo $k$ es utilizado para entrenar y el resto para evaluar, repitiéndose el proceso $k$ veces, donde un grupo $k_i$ es utilizado solo una vez para entrenar. El valor final estimado de la métrica es el promedio de los valores obtenidos de cada grupo.   

$$\hat{M} = \frac{1}{k} \sum_{i=1}^{k} M_i$$

Donde:


• $\hat{M}$ es el valor estimado de la métrica de evaluación.

• $k$ es la cantidad de grupos en los que se dividió el conjunto de datos.

• $M_i$ es el valor de la métrica de evaluación obtenido en el $i$-ésimo grupo utilizado como conjunto de prueba.


Dentro de este trabajo no sólo se evaluaran distintos modelos, sino que se utilizaran distintos \textit{datasets} para lograrlos.

\section{Métricas para caso Binario}

\subsection{Matriz de Confusión}

Una matriz de confusión es una forma simple de saber de que forma esta clasificando el algoritmo, donde una clase es considerada \textbf{positiva $P$} y la otra \textbf{negativa $N$}. La matriz de confusión clasifica las predicciones en:

\begin{itemize}
	\item \textbf{Verdaderos Positivos (TP):} Casos positivos clasificados correctamente.\\
	\item \textbf{Verdaderos Negativos (TN):} Casos negativos clasificados correctamente.\\
	\item \textbf{Falsos Positivos (FP):} Casos negativos clasificados incorrectamente como positivos.\\
	\item \textbf{Falsos Negativos (FN):} Casos positivos clasificados incorrectamente como positivos. \\
\end{itemize}



\begin{center}
	\renewcommand{\arraystretch}{1.5} 
	\begin{tabular}{|c|c|c|c|}
		\cline{3-4}
		\multicolumn{2}{c|}{} & \multicolumn{2}{c|}{\textbf{Predicción}} \\
		\cline{3-4}
		\multicolumn{2}{c|}{} & \textbf{Positivo} & \textbf{Negativo} \\
		\hline
		\multirow{2}{*}{\textbf{Verdad}} & \textbf{Positivo} & \cellcolor{TPcolor} \textbf{Verdadero Positivo (TP)} & \cellcolor{FNcolor} \textbf{Falso Negativo (FN)} \\
		\cline{2-4}
		& \textbf{Negativo} & \cellcolor{FNcolor} \textbf{Falso Positivo (FP)} & \cellcolor{TPcolor} \textbf{Verdadero Negativo (TN)} \\
		\hline
	\end{tabular}
\end{center}

\subsection{\textit{Accuracy}}

El \textit{Accuracy} es la proporción de instancias clasificadas correctamente, es una medida "ingenua" que puede ser engañosa si existe un gran desbalance entre clases.

En términos de la Matriz de Confusión:

$$\text{Accuracy} = \frac{TP + TN}{TP + FP + TN + FN} = \frac{TP + TN}{\text{Total}}$$

En términos del conjunto de predicciones y valores verdaderos:

$$\texttt{accuracy}(y, \hat{y}) = \frac{1}{n_\text{samples}} \sum_{i=0}^{n_\text{samples}-1} 1(\hat{y}_i = y_i) $$

Donde:

• $n_{\text{samples}}$: Representa la cantidad total de ejemplos en la muestra

•  $\hat{y}_i$ y $y_i$: $\hat{y}_i$ es el valor predicho del $i$-ésimo ejemplo, y $y_i$ es el valor verdadero correspondiente

por lo tanto, calcula:

$$\text{Accuracy} = \frac{\text{Número de predicciones correctas}}{\text{Número total de muestras}}$$

\subsection{\textit{Precision}}

El \textit{Precision} mide la probabilidad de que la predicción positiva del clasificador sea correcta.

En términos de la Matriz de Confusión:

$$ \text{Precision} = \frac{TP}{TP + FP} $$

\subsection{\textit{Recall}}

El \textit{Recall} o también conocido como Sensibilidad o Tasa de Verdaderos Negativos (TPR). Mide la probabilidad de que el clasificador detecte un caso positivo cuando en verdad lo es.

En términos de la Matriz de Confusión:

$$ \text{Recall} = TPR = \frac{TP}{TP + FN} = \frac{TP}{P} $$

\subsection{\textit{F-measure}}

El \textit{F-measure} es la media armónica ponderada de \textit{precision} y \textit{recall}. La versión más común es el \textbf{F1-score}, donde el parámetro de ponderación $\beta$ es igual a 1. Un clasificador perfecto tiene un valor $F1 = 1$.


Fórmula General ($F_{\beta}$):

$$F_{\beta} = \frac{(1 + \beta^2) \text{precision} \times \text{recall}}{\beta^2 \text{precision} + \text{recall}}$$

Fórmula del F1-score ($\beta=1$) en términos de Precision y Recall: 

$$F1 = 2 \cdot \frac{\text{precision} \cdot \text{recall}}{\text{precision} + \text{recall}}$$

En términos de la Matriz de Confusión:

$$ F1 = \frac{2TP}{2TP + FP + FN} $$

\subsection{\textit{Recall}}

El \textit{Recall} o también conocido como Sensibilidad o Tasa de Verdaderos Negativos (TPR). Mide la probabilidad de que el clasificador detecte un caso positivo cuando en verdad lo es.

En términos de la Matriz de Confusión:

$$ \text{Recall} = TPR = \frac{TP}{TP + FN} = \frac{TP}{P} $$

\subsection{\textit{Área Bajo la Curva ROC (ROC AUC)}}

La métrica \textit{ROC AUC} es un valor que resume la capacidad de un clasificador para distinguir entre clases.

\textbf{La Curva ROC} es un gráfico que ilustra el rendimiento de un clasificador binario a media que se varia su umbral de discriminación Se crea graficando la \textbf{Tasa de Verdaderos Positivos (TPR)} versus la \textbf{Tasa de Falsos Positivos (FPR)} en varios umbrales.

Ejes utlizados para el gráfico:

• \textbf{Eje Y:} TPR

• \textbf{Eje X:} FPR

El \textbf{AUC} mide justamente el área debajo de la Curva ROC. El AUC se utiliza para comparar el desempeño de diferentes modelos de clasificación.

Interpretación de valores:

• Un clasificador ideal se ubica en el punto $(0, 1)$, donde $TPR=1$ y $FPR=0$, lo que resulta en un \textbf{$AUC = 1$} 

• Un clasificador aleatorio se sitúa sobre la línea $TPR = FPR$, lo que resulta en un \textbf{$AUC = 0.5$}

•  Un clasificador se considera razonable si \textbf{ $0.5 < AUC \leq 1$}



\section{Métricas para caso Multiclase}

En este caso se utiliza el método \textit{"weighted"}, el cual computa el desequilibrio de clases calculando el promedio de métricas binarias en las que la puntuación de cada clase se pondera según su presencia en la muestra de datos reales.

La métrica ponderada por la presencia de la clase, $\text{M}_{\text{weighted}}$, se calcula como el promedio de la métrica por clase $\text{M}_l$, donde cada contribución es ponderada por el tamaño de la clase $|y_l|$:


$$\hat{M}_{\text{weighted}} = \frac{1}{\sum{l \in L} |y_l|} \sum_{l \in L} |y_l| \cdot \text{M}_l$$

Donde:

• $\hat{M}_{\text{weighted}}$ es el valor estimado de la métrica promedio ponderada.

• $L$ es el conjunto de etiquetas o clases.

• $|y_l|$ es el soporte o cantidad de muestras verdaderas que tienen la etiqueta $l$.

• $\sum_{l \in L} |y_l|$ representa el número total de pares (muestra, etiqueta) verdaderos en el conjunto de datos.

• $\text{M}l$ es el valor de la métrica binaria (como Precisión,  o $F{\beta}$-score) calculado para la clase individual $l$

\subsection{Matriz de Confusión (Multiclase)}

La matriz de confusión multiclase es una matriz cuadrada de tamaño $L \times L$, donde $L$ es el número de clases. Cada celda $C_{ij}$ representa la cantidad de muestras verdaderamente pertenecientes a la clase $i$ que fueron clasificadas como clase $j$.

Para cada clase $l$ se definen los valores:

\begin{align*} TP_l &= C_{ll} \ FP_l &= \sum_{i \neq l} C_{il} \ FN_l &= \sum_{j \neq l} C_{lj} \ TN_l &= N - TP_l - FP_l - FN_l \end{align*}


\subsection{\textit{Precision}}

La \textit{Precision} por clase $l$ mide la proporción de muestras clasificadas como positivas que realmente pertenecen a la clase $l$:

En términos de la Matriz de Confusión:


$$\text{Precision}_l = \frac{TP_l}{TP_l + FP_l}$$

\subsection{\textit{Recall}}

El \textit{Recall} por clase $l$ mide la proporción de muestras verdaderamente positivas de la clase $l$ que fueron correctamente identificadas:

En términos de la Matriz de Confusión:

$$ \text{Recall}_l = \frac{TP_l}{TP_l + FN_l} $$

\subsection{\textit{F-measure}}

El \textit{F-measure} es la media armónica ponderada de \textit{precision} y \textit{recall}. La versión más común es el \textbf{F1-score}, donde el parámetro de ponderación $\beta$ es igual a 1. Un clasificador perfecto tiene un valor $F1 = 1$.


Fórmula del F1-score ($\beta=1$) en términos de Precision y Recall: 

$$F1 = 2 \cdot \frac{\text{precision} \cdot \text{recall}}{\text{precision} + \text{recall}}$$

El valor global ponderado se obtiene aplicando la fórmula de $M_{\text{weighted}}$ sobre los $F_{1,l}$:

$$ F_{1,\text{weighted}} = \sum_{l \in L} w_l \, F_{1,l}, \quad 
\text{con } w_l = \frac{n_l}{\sum_{i \in L} n_i} $$


\subsection{\textit{Área Bajo la Curva ROC (ROC AUC)}}

Para extender la métrica ROC AUC a clasificación multiclase se emplea el enfoque \textbf{One-vs-Rest (OVR)}:

\begin{itemize}
	\item Para cada clase $l$, se considera la clase $l$ como positiva y el resto como negativas.
	\item Se calcula el AUC correspondiente ($\text{AUC}_l$) sobre la curva ROC de esa clasificación binaria.
	\item Finalmente, se obtiene un promedio ponderado por el soporte de cada clase:
\end{itemize}

$$ \text{AUC}_{\text{OVR, weighted}} = \sum_{l \in L} w_l \, \text{AUC}_l $$

donde:

$$ w_l = \frac{n_l}{\sum_{i \in L} n_i}  $$























\chapter{Descripción de los Métodos Utilizados}







{\color{blue}
\section{Regresión Logística}
El modelo de Regresión Logística (LR, por su equivalente en inglés \emph{Logistic Regresion}).....

Se consideraron los siguientes valores para los hiperparámetros....

El mejor rendimiento se obtuvo con... Notamos este modelo como $\text{RL}^{\text{opt}}$.

$\mathcal{C} C$} 



\chapter{Resultados}

Mostrar los resultados obtenidos utilizando gráficos, tablas, figuras, etc

\section{Introducción}
Primera aproximación a resultados.



\section{Métricas de Evaluación}
A continuación se muestran las mejores métricas obtenidas, ademas del grid utilizado.

\subsection{Dataset Binario}

\subsection{Regresión Logística}
\begin{itemize}
    \item \textbf{Precisión (Acc):} 0.84
    \item \textbf{F1 Score:} 0.84
    \item \textbf{ROC AUC:} 0.90
\end{itemize}

\textbf{Grid de Hiperparámetros:}
\begin{itemize}
    \item $C = [0, 0.1, 0.01]$
    \item \textbf{Penalty:} None, l1, l2, elasticnet
    \item \textbf{Solver:} lbfgs, saga, newton-s
    \item \textbf{Multiclass:} ovr, multinomial
\end{itemize}

\textbf{Mejor Configuración:}
\begin{itemize}
    \item $C = 1$, Penalty = l1, Solver = lbfgs, saga, $[Multiclass = ovr, multinomial]$
\end{itemize}

\subsection{Máquinas de Soporte Vectorial (SVM)}
\begin{itemize}
    \item \textbf{Precisión (Acc):} 0.861
    \item \textbf{F1 Score:} 0.86
    \item \textbf{Recall:} 0.86
\end{itemize}

\textbf{Grid de Hiperparámetros:}
\begin{itemize}
    \item $C = [0.001, 0.01, 0.1, 1, 10, 15, 20, 25]$
    \item \textbf{Kernel:} $[linear, poly, rb", sigmoid] $
    \item \textbf{Gamma:} $ [scale, auto, 0.001, 0.01, 0.1, 1] $
    \item \textbf{Degree:} $ [2,3,4,5,6,7,8,9,10] $
\end{itemize}

\textbf{Mejor Configuración:}
\begin{itemize}
    \item $C = 1$, kernel = rbf, gamma = scale
\end{itemize}

\subsection{Naive Bayes Gaussiano}
\begin{itemize}
    \item \textbf{Precisión (Acc):} 0.84
    \item \textbf{F1 Score:} 0.84
\end{itemize}

\textbf{Grid de Hiperparámetros:}
\begin{itemize}
    \item \textbf{Suavizado:} Cualquier suavizado
\end{itemize}

\textbf{Mejor Configuración:}
\begin{itemize}
        \item Suavizado: Cualquiera
\end{itemize}

\subsection{Random Forest}
\begin{itemize}
    \item \textbf{Precisión (Acc):} 0.878
    \item \textbf{F1 Score:} 0.877
    \item \textbf{ROC AUC:} 0.92
\end{itemize}

\textbf{Grid de Hiperparámetros:}
\begin{itemize}
    \item \textbf{Criterion:} $[gini, entropy]$
    \item \textbf{Max Depth:} $ [None, 3, 5, 7, 9] $
    \item \textbf{Min Samples Split:} $ [2, 5, 10]$
    \item \textbf{Min Samples Leaf:} $[1, 2, 4] $
    \item \textbf{Max Features:} $ [None, sqrt, log2] $
\end{itemize}

\textbf{Mejor Configuración:}
\begin{itemize}
        \item Criterion: entropy, Maxdeph = 7, min samples split = 5, min samples leaf 1, max features = sqrt, log2.
\end{itemize}

\section{Importancia de las Características}
La importancia de las características de las mejores configuraciones.

\subsection{Random Forest}
\begin{longtable}{|l|c|}
\hline
\textbf{Característica} & \textbf{Importancia} \\
\hline
ST\_Slope & 0.254265 \\
ChestPainType & 0.127319 \\
Oldpeak & 0.113156 \\
ExerciseAngina & 0.105952 \\
Cholesterol & 0.099872 \\
MaxHR & 0.088635 \\
Age & 0.065807 \\
RestingBP & 0.055053 \\
Sex & 0.040916 \\
FastingBS & 0.030069 \\
RestingECG & 0.018956 \\
\hline
\end{longtable}

\subsection{Regresión Logística}
\begin{longtable}{|l|c|}
\hline
\textbf{Característica} & \textbf{Importancia (Permutación)} \\
\hline
Oldpeak & 0.045643 \\
ChestPainType & 0.036383 \\
MaxHR & 0.030174 \\
Cholesterol & 0.026797 \\
ST\_Slope & 0.026580 \\
ExerciseAngina & 0.013181 \\
Age & 0.008279 \\
Sex & 0.002941 \\
RestingECG & 0.002179 \\
RestingBP & 0.001634 \\
FastingBS & 0.001525 \\
\hline
\end{longtable}

\subsection{SVM}
\begin{longtable}{|l|c|}
\hline
\textbf{Característica} & \textbf{Importancia (Permutación)} \\
\hline
MaxHR & 0.103704 \\
Cholesterol & 0.070915 \\
Age & 0.007081 \\
RestingBP & 0.002723 \\
Oldpeak & 0.000871 \\
ChestPainType & 0.000218 \\
Sex & 0.000000 \\
RestingECG & 0.000000 \\
FastingBS & 0.000000 \\
ExerciseAngina & 0.000000 \\
ST\_Slope & -0.000218 \\
\hline
\end{longtable}

\subsection{Naive Bayes Gaussiano}
\begin{longtable}{|l|c|}
\hline
\textbf{Característica} & \textbf{Importancia (Permutación)} \\
\hline
ST\_Slope & 0.027015 \\
ExerciseAngina & 0.023747 \\
Oldpeak & 0.018736 \\
ChestPainType & 0.018519 \\
Cholesterol & 0.014815 \\
Sex & 0.014270 \\
FastingBS & 0.004575 \\
RestingBP & 0.001852 \\
MaxHR & -0.000218 \\
RestingECG & -0.001198 \\
Age & -0.003595 \\
\hline
\end{longtable}

\subsection{Importancia de las Características (Coeficientes Absolutos de Regresión Logística)}
\begin{longtable}{|l|c|}
\hline
\textbf{Característica} & \textbf{Importancia (Coeficientes)} \\
\hline
Oldpeak & 0.399451 \\
ChestPainType & 0.397051 \\
ST\_Slope & 0.386263 \\
ExerciseAngina & 0.268956 \\
Sex & 0.150576 \\
FastingBS & 0.119947 \\
RestingECG & 0.034868 \\
Age & 0.024577 \\
MaxHR & 0.019045 \\
RestingBP & 0.007427 \\
Cholesterol & 0.003631 \\
\hline
\end{longtable}


\subsection{Dataset Multiclase}

\subsection{Regresión Logística}
\begin{itemize}
    \item \textbf{Precisión (Acc):} 0.897
    \item \textbf{F1 Score:} 0.0.8956
\end{itemize}

\textbf{Grid de Hiperparámetros:}
\begin{itemize}
    \item $C = [0, 0.1, 0.01]$
    \item \textbf{Penalty:} None, l1, l2, elasticnet
    \item \textbf{Solver:} lbfgs, saga, newton-s
    \item \textbf{Multiclass:} ovr, multinomial
\end{itemize}

\textbf{Mejor Configuración:}
\begin{itemize}
    \item $C = [0.01, 0.1, 10] $, Penalty = $[None,l2(C=10),elasticnet(C=10)] $ , Solver = $[ lbfgs, saga, newton-s]$ , $[Multiclass = ovr]$
\end{itemize}

\subsection{Máquinas de Soporte Vectorial (SVM)}
\begin{itemize}
    \item \textbf{Precisión (Acc):} 0.0.861
    \item \textbf{F1 Score:} 0.86
\end{itemize}

\textbf{Grid de Hiperparámetros:}
\begin{itemize}
    \item $C = [0.001, 0.01, 0.1, 1, 10, 15, 20, 25]$
    \item \textbf{Kernel:} $[linear, poly, rb", sigmoid] $
    \item \textbf{Gamma:} $ [scale, auto, 0.001, 0.01, 0.1, 1] $
    \item \textbf{Degree:} $ [2,3,4,5,6,7,8,9,10] $
\end{itemize}

\textbf{Mejor Configuración:}
\begin{itemize}
    \item $C = 1$, kernel = rbf, gamma = scale
\end{itemize}

\subsection{Naive Bayes Gaussiano}
\begin{itemize}
    \item \textbf{Precisión (Acc):} 0.822
    \item \textbf{F1 Score:} 0.83
\end{itemize}

\textbf{Grid de Hiperparámetros:}
\begin{itemize}
    \item \textbf{Suavizado:} Cualquier suavizado
\end{itemize}

\textbf{Mejor Configuración:}
\begin{itemize}
        \item Suavizado: Cualquiera
\end{itemize}

\subsection{Random Forest}
\begin{itemize}
    \item \textbf{Precisión (Acc):} 0.943
    \item \textbf{F1 Score:} 0.94
\end{itemize}

\textbf{Grid de Hiperparámetros:}
\begin{itemize}
    \item \textbf{Criterion:} $[gini, entropy]$
    \item \textbf{Max Depth:} $ [None, 3, 5, 7, 9] $
    \item \textbf{Min Samples Split:} $ [2, 5, 10]$
    \item \textbf{Min Samples Leaf:} $[1, 2, 4] $
    \item \textbf{Max Features:} $ [None, sqrt, log2] $
\end{itemize}

\textbf{Mejor Configuración:}
\begin{itemize}
        \item Criterion: $[entropy, gini]$, Maxdeph = $None$, min samples split = $[2,5] $, min samples leaf 1, max features = $[sqrt, log2]$.
\end{itemize}

\section{Importancia de las Características}
La importancia de las características de las mejores configuraciones.

\subsection{Random Forest}
\begin{longtable}{|l|c|}
\hline
\textbf{Característica} & \textbf{Importancia} \\
\hline

ASTV      &  0.139807\\
ALTV      &  0.109941\\
MSTV      &  0.104823\\
Mean      &  0.091579\\
AC        &  0.063645\\
Mode       & 0.061986\\
Median      &0.060633\\
DP        &  0.047945\\
LB        &  0.045324\\
MLTV      &  0.045132\\
Variance  &  0.040531\\
UC        &  0.039166\\
Width     &  0.030551\\
Min       &  0.030109\\
Max       &  0.027147\\
FM        &  0.020801\\
Nmax      &  0.018407\\
DL        &  0.011128\\
Tendency  &  0.007652\\
Nzeros    &  0.003405\\
DS        &  0.000287\\

\hline
\end{longtable}

\textbf{Atributos que mejoran accuracy:} $ [][ASTV,ALTV,MSTV,Mean,AC,Mode,Median,DP,LB,Variance] $

\subsection{Regresión Logística}
\begin{longtable}{|l|c|}
\hline
\textbf{Característica} & \textbf{Importancia (Permutación)} \\
\hline

Mean    &    0.098487\\
AC       &   0.084113\\
ASTV     &   0.057069\\
Median   &   0.031631\\
DP       &   0.029740\\
LB       &   0.023404\\
Variance &   0.022270\\
UC       &   0.022080\\
ALTV     &   0.019243\\
Max      &   0.018109\\
Nmax     &   0.014374\\
Mode     &   0.011348\\
Min      &   0.005910\\
MSTV     &   0.004208\\
FM       &   0.003830\\
Tendency &   0.003546\\
MLTV     &   0.002979\\
Nzeros   &   0.002837\\
DL       &   0.001655\\
Width    &   0.000189\\
DS       &   0.000000\\

\hline
\end{longtable}

\subsection{SVM}
\begin{longtable}{|l|c|}
\hline
\textbf{Característica} & \textbf{Importancia (Permutación)} \\
\hline
ASTV     &   0.050355\\
ALTV     &   0.037069\\
UC       &   0.030638\\
AC       &   0.026903\\
DP       &   0.018345\\
Mean     &   0.015887\\
Mode     &   0.014988\\
Median   &   0.014043\\
Nmax     &   0.011915\\
MSTV     &   0.009125\\
DL       &   0.005059\\
Variance &   0.004775\\
Nzeros   &   0.004586\\
Min      &   0.004444\\
Max      &   0.004350\\
MLTV     &   0.003357\\
Tendency &   0.003026\\
FM       &   0.002459\\
Width    &   0.001418\\
DS       &   0.000000\\
LB       &  -0.000804\\

\hline
\end{longtable}

\subsection{Naive Bayes Gaussiano}
\begin{longtable}{|l|c|}
\hline
\textbf{Característica} & \textbf{Importancia (Permutación)} \\
\hline
AC      &    0.057163\\
DP       &   0.018676\\
ALTV     &   0.015461\\
ASTV     &   0.005106\\
DS       &   0.002695\\
UC       &   0.002364\\
FM       &   0.001371\\
Variance &   0.001087\\
Nzeros   &   0.001040\\
Nmax     &  -0.000993\\
Tendency &  -0.001040\\
Mode     &  -0.001324\\
Max      &  -0.001371\\
Min      &  -0.001986\\
LB       &  -0.001986\\
MLTV     &  -0.002222\\
Width    &  -0.002459\\
Median   &  -0.003310\\
MSTV     &  -0.004965\\
Mean     &  -0.005768\\
DL       &  -0.006809\\

\hline
\end{longtable}

\subsection{Importancia de las Características (Coeficientes Absolutos de Regresión Logística)}
\begin{longtable}{|l|c|}
\hline
\textbf{Característica} & \textbf{Importancia (Coeficientes)} \\
\hline
AC         & 3.619754\\
Mean      &  2.520677\\
LB        &  1.134264\\
ASTV      &  0.867591\\
Variance  &  0.547877\\
Nmax      &  0.522037\\
UC        &  0.514121\\
Max       &  0.468159\\
DP        &  0.309519\\
Min       &  0.245054\\
MSTV      &  0.233617\\
Mode      &  0.216870\\
Median    &  0.143711\\
MLTV      &  0.121284\\
Nzeros    &  0.103791\\
DL        &  0.076451\\
Tendency  &  0.071444\\
Width     & 0.029727\\
ALTV      &  0.025537\\
FM        &  0.024773\\
DS        &  0.000035\\
\hline
\end{longtable}

\chapter{Conclusiones}

Explicar que aprendimos con la realización de este trabajo. Qué nos muestran los resultados. 

\bibliographystyle{plain}
\bibliography{References}

\end{document}
